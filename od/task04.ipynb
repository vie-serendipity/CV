{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# 训练与测试"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 训练\n",
    "+ 设置各种超参数\n",
    "+ 定义数据加载模块 dataloader\n",
    "+ 定义网络 model\n",
    "+ 定义损失函数 loss\n",
    "+ 定义优化器 optimizer\n",
    "+ 遍历训练数据，预测-计算loss-反向传播"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "```python\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Training.\n",
    "    \"\"\"\n",
    "    # Initialize model and optimizer\n",
    "    model = tiny_detector(n_classes=n_classes)\n",
    "    criterion = MultiBoxLoss(priors_cxcy=model.priors_cxcy)\n",
    "    optimizer = torch.optim.SGD(params=model.parameters(),\n",
    "                                lr=lr, \n",
    "                                momentum=momentum,\n",
    "                                weight_decay=weight_decay)\n",
    "\n",
    "    # Move to default device\n",
    "    model = model.to(device)\n",
    "    criterion = criterion.to(device)\n",
    "\n",
    "    # Custom dataloaders\n",
    "    train_dataset = PascalVOCDataset(data_folder,\n",
    "                                     split='train',\n",
    "                                     keep_difficult=keep_difficult)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset,   \n",
    "                                    batch_size=batch_size,\n",
    "                                    shuffle=True,\n",
    "                                    collate_fn=train_dataset.collate_fn, \n",
    "                                    num_workers=workers,\n",
    "                                    pin_memory=True) \n",
    "\n",
    "    # Epochs\n",
    "    for epoch in range(total_epochs):\n",
    "        # Decay learning rate at particular epochs\n",
    "        if epoch in decay_lr_at:\n",
    "            adjust_learning_rate(optimizer, decay_lr_to)\n",
    "\n",
    "        # One epoch's training                                                                                                                 \n",
    "        train(train_loader=train_loader,\n",
    "              model=model,\n",
    "              criterion=criterion,\n",
    "              optimizer=optimizer,\n",
    "              epoch=epoch)\n",
    "\n",
    "        # Save checkpoint\n",
    "        save_checkpoint(epoch, model, optimizer)\n",
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    \"\"\"\n",
    "    One epoch's training.\n",
    "\n",
    "    :param train_loader: DataLoader for training data\n",
    "    :param model: model\n",
    "    :param criterion: MultiBox loss\n",
    "    :param optimizer: optimizer\n",
    "    :param epoch: epoch number\n",
    "    \"\"\"\n",
    "    model.train()  # training mode enables dropout\n",
    "\n",
    "    batch_time = AverageMeter()  # forward prop. + back prop. time\n",
    "    data_time = AverageMeter()  # data loading time\n",
    "    losses = AverageMeter()  # loss\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    # Batches\n",
    "    for i, (images, boxes, labels, _) in enumerate(train_loader):\n",
    "        data_time.update(time.time() - start)\n",
    "\n",
    "        # Move to default device\n",
    "        images = images.to(device)  # (batch_size (N), 3, 224, 224)\n",
    "        boxes = [b.to(device) for b in boxes]\n",
    "        labels = [l.to(device) for l in labels]\n",
    "\n",
    "        # Forward prop.\n",
    "        predicted_locs, predicted_scores = model(images)  # (N, 441, 4), (N, 441, n_classes)\n",
    "\n",
    "        # Loss\n",
    "        loss = criterion(predicted_locs, predicted_scores, boxes, labels)  # scalar\n",
    "\n",
    "        # Backward prop.\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # Update model\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.update(loss.item(), images.size(0))\n",
    "        batch_time.update(time.time() - start)\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        # Print status\n",
    "        if i % print_freq == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Batch Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data Time {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'.format(epoch,\n",
    "                                                                  i, \n",
    "                                                                  len(train_loader),\n",
    "                                                                  batch_time=batch_time,\n",
    "                                                                  data_time=data_time, \n",
    "                                                                  loss=losses))\n",
    "    del predicted_locs, predicted_scores, images, boxes, labels  # free some memory since their histories may be stored\n",
    "\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 后处理\n",
    "+ NMS 非极大值抑制\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "```python\n",
    "def detect_objects(self, predicted_locs, predicted_scores, min_score, max_overlap, top_k):\n",
    "    \"\"\"                                                                                                                                                       \n",
    "    Decipher the 441 locations and class scores (output of the tiny_detector) to detect objects.\n",
    "\n",
    "    For each class, perform Non-Maximum Suppression (NMS) on boxes that are above a minimum threshold.\n",
    "\n",
    "    :param predicted_locs: predicted locations/boxes w.r.t the 441 prior boxes, a tensor of dimensions (N, 441, 4)\n",
    "    :param predicted_scores: class scores for each of the encoded locations/boxes, a tensor of dimensions (N, 441, n_classes)\n",
    "    :param min_score: minimum threshold for a box to be considered a match for a certain class\n",
    "    :param max_overlap: maximum overlap two boxes can have so that the one with the lower score is not suppressed via NMS\n",
    "    :param top_k: if there are a lot of resulting detection across all classes, keep only the top 'k'\n",
    "    :return: detections (boxes, labels, and scores), lists of length batch_size\n",
    "    \"\"\"\n",
    "    batch_size = predicted_locs.size(0)\n",
    "    n_priors = self.priors_cxcy.size(0)\n",
    "    predicted_scores = F.softmax(predicted_scores, dim=2)  # (N, 441, n_classes)\n",
    "\n",
    "    # Lists to store final predicted boxes, labels, and scores for all images in batch\n",
    "    all_images_boxes = list()\n",
    "    all_images_labels = list()\n",
    "    all_images_scores = list()\n",
    "\n",
    "    assert n_priors == predicted_locs.size(1) == predicted_scores.size(1)\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        # Decode object coordinates from the form we regressed predicted boxes to\n",
    "        decoded_locs = cxcy_to_xy(                                                                                                                            \n",
    "            gcxgcy_to_cxcy(predicted_locs[i], self.priors_cxcy))  # (441, 4), these are fractional pt. coordinates\n",
    "\n",
    "        # Lists to store boxes and scores for this image\n",
    "        image_boxes = list()\n",
    "        image_labels = list()\n",
    "        image_scores = list()\n",
    "\n",
    "        max_scores, best_label = predicted_scores[i].max(dim=1)  # (441)\n",
    "\n",
    "        # Check for each class\n",
    "        for c in range(1, self.n_classes):\n",
    "            # Keep only predicted boxes and scores where scores for this class are above the minimum score\n",
    "            class_scores = predicted_scores[i][:, c]  # (441)\n",
    "            score_above_min_score = class_scores > min_score  # torch.uint8 (byte) tensor, for indexing\n",
    "            n_above_min_score = score_above_min_score.sum().item()\n",
    "            if n_above_min_score == 0:\n",
    "                continue\n",
    "            class_scores = class_scores[score_above_min_score]  # (n_qualified), n_min_score <= 441\n",
    "            class_decoded_locs = decoded_locs[score_above_min_score]  # (n_qualified, 4)\n",
    "\n",
    "            # Sort predicted boxes and scores by scores\n",
    "            class_scores, sort_ind = class_scores.sort(dim=0, descending=True)  # (n_qualified), (n_min_score)\n",
    "            class_decoded_locs = class_decoded_locs[sort_ind]  # (n_min_score, 4)\n",
    "\n",
    "            # Find the overlap between predicted boxes\n",
    "            overlap = find_jaccard_overlap(class_decoded_locs, class_decoded_locs)  # (n_qualified, n_min_score)\n",
    "\n",
    "            # Non-Maximum Suppression (NMS)\n",
    "\n",
    "            # A torch.uint8 (byte) tensor to keep track of which predicted boxes to suppress\n",
    "            # 1 implies suppress, 0 implies don't suppress\n",
    "            suppress = torch.zeros((n_above_min_score), dtype=torch.uint8).to(device)  # (n_qualified)\n",
    "\n",
    "            # Consider each box in order of decreasing scores\n",
    "            for box in range(class_decoded_locs.size(0)):\n",
    "                # If this box is already marked for suppression\n",
    "                if suppress[box] == 1:\n",
    "                    continue\n",
    "\n",
    "                # Suppress boxes whose overlaps (with current box) are greater than maximum overlap\n",
    "                # Find such boxes and update suppress indices\n",
    "                suppress = torch.max(suppress, (overlap[box] > max_overlap).to(torch.uint8))\n",
    "                # The max operation retains previously suppressed boxes, like an 'OR' operation\n",
    "\n",
    "                # Don't suppress this box, even though it has an overlap of 1 with itself\n",
    "                suppress[box] = 0\n",
    "\n",
    "            # Store only unsuppressed boxes for this class\n",
    "            image_boxes.append(class_decoded_locs[1 - suppress])\n",
    "            image_labels.append(torch.LongTensor((1 - suppress).sum().item() * [c]).to(device))\n",
    "            image_scores.append(class_scores[1 - suppress])\n",
    "\n",
    "        # If no object in any class is found, store a placeholder for 'background'\n",
    "        if len(image_boxes) == 0:\n",
    "            image_boxes.append(torch.FloatTensor([[0., 0., 1., 1.]]).to(device))\n",
    "            image_labels.append(torch.LongTensor([0]).to(device))\n",
    "            image_scores.append(torch.FloatTensor([0.]).to(device))\n",
    "\n",
    "        # Concatenate into single tensors\n",
    "        image_boxes = torch.cat(image_boxes, dim=0)  # (n_objects, 4)\n",
    "        image_labels = torch.cat(image_labels, dim=0)  # (n_objects)\n",
    "        image_scores = torch.cat(image_scores, dim=0)  # (n_objects)\n",
    "        n_objects = image_scores.size(0)\n",
    "\n",
    "        # Keep only the top k objects\n",
    "        if n_objects > top_k:\n",
    "            image_scores, sort_ind = image_scores.sort(dim=0, descending=True)\n",
    "            image_scores = image_scores[:top_k]  # (top_k)\n",
    "            image_boxes = image_boxes[sort_ind][:top_k]  # (top_k, 4)\n",
    "            image_labels = image_labels[sort_ind][:top_k]  # (top_k)\n",
    "\n",
    "        # Append to lists that store predicted boxes and scores for all images\n",
    "        all_images_boxes.append(image_boxes)\n",
    "        all_images_labels.append(image_labels)\n",
    "        all_images_scores.append(image_scores)\n",
    "\n",
    "    return all_images_boxes, all_images_labels, all_images_scores  # lists of length batch_size\n",
    "\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 预测"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "```python\n",
    "# Transform the image\n",
    "image = normalize(to_tensor(resize(original_image)))\n",
    "\n",
    "# Move to default device\n",
    "image = image.to(device)\n",
    "\n",
    "# Forward prop.\n",
    "predicted_locs, predicted_scores = model(image.unsqueeze(0))\n",
    "\n",
    "# Post process, get the final detect objects from our tiny detector output\n",
    "det_boxes, det_labels, det_scores = model.detect_objects(predicted_locs, predicted_scores, min_score=min_score, max_overlap=max_overlap, top_k=top_k)\n",
    "\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 指标\n",
    "+ recall/precision\n",
    "$$precision=\\frac{TP}{TP+FP}    , recall=\\frac{TP}{TP+FN}$$\n",
    "+ F1-score\n",
    " $$\\frac{2PR}{P+R}$$\n",
    "+ RP曲线\n",
    "+ mAP\n",
    "\n",
    "AP为RP曲线下的面积，mAP为各个种类的均值"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}